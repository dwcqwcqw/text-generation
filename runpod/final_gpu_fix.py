#!/usr/bin/env python3
"""
æœ€ç»ˆGPUä¿®å¤è„šæœ¬ - è§£å†³CPU_AARCH64æ¶æ„é—®é¢˜
ç¡®ä¿æ‰€æœ‰æ¨¡å‹å±‚éƒ½åŠ è½½åˆ°GPUè€Œä¸æ˜¯CPU
"""

import os
import sys
import subprocess
import logging
import platform

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def check_system_architecture():
    """æ£€æŸ¥ç³»ç»Ÿæ¶æ„"""
    arch = platform.machine()
    logger.info(f"ğŸ” ç³»ç»Ÿæ¶æ„: {arch}")
    
    if arch == 'aarch64' or arch == 'arm64':
        logger.error("âŒ æ£€æµ‹åˆ°ARM64æ¶æ„ï¼Œè¿™ä¼šå¯¼è‡´CPU_AARCH64é”™è¯¯")
        logger.info("ğŸ”§ å¼ºåˆ¶è®¾ç½®x86_64ç¯å¢ƒå˜é‡...")
        
        # å¼ºåˆ¶è®¾ç½®x86_64ç¯å¢ƒå˜é‡
        os.environ['ARCHFLAGS'] = '-arch x86_64'
        os.environ['CFLAGS'] = '-march=x86-64'
        os.environ['CXXFLAGS'] = '-march=x86-64'
        os.environ['CMAKE_OSX_ARCHITECTURES'] = 'x86_64'
        
        return False
    elif arch == 'x86_64':
        logger.info("âœ… æ­£ç¡®çš„x86_64æ¶æ„")
        return True
    else:
        logger.warning(f"âš ï¸ æœªçŸ¥æ¶æ„: {arch}")
        return False

def setup_cuda_environment():
    """è®¾ç½®CUDAç¯å¢ƒå˜é‡"""
    logger.info("ğŸ”§ è®¾ç½®CUDAç¯å¢ƒå˜é‡...")
    
    cuda_env = {
        'CUDA_VISIBLE_DEVICES': '0',
        'GGML_CUDA': '1',
        'CMAKE_CUDA_ARCHITECTURES': '75;80;86;89',
        'FORCE_CMAKE': '1',
        'CMAKE_ARGS': '-DGGML_CUDA=ON -DCMAKE_CUDA_ARCHITECTURES=75;80;86;89',
        'ARCHFLAGS': '-arch x86_64',
        'CFLAGS': '-march=x86-64',
        'CXXFLAGS': '-march=x86-64'
    }
    
    for key, value in cuda_env.items():
        os.environ[key] = value
        logger.info(f"  âœ“ {key}={value}")

def check_nvidia_driver():
    """æ£€æŸ¥NVIDIAé©±åŠ¨"""
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            logger.info("âœ… NVIDIAé©±åŠ¨æ­£å¸¸")
            # è§£æGPUä¿¡æ¯
            lines = result.stdout.split('\n')
            for line in lines:
                if 'RTX' in line or 'Tesla' in line or 'L4' in line or 'L40' in line:
                    logger.info(f"ğŸ¯ æ£€æµ‹åˆ°GPU: {line.strip()}")
            return True
        else:
            logger.error("âŒ nvidia-smiå‘½ä»¤å¤±è´¥")
            return False
    except Exception as e:
        logger.error(f"âŒ NVIDIAé©±åŠ¨æ£€æŸ¥å¤±è´¥: {e}")
        return False

def reinstall_llama_cpp_python():
    """é‡æ–°å®‰è£…GPUç‰ˆæœ¬çš„llama-cpp-python"""
    logger.info("ğŸ”„ é‡æ–°å®‰è£…GPUç‰ˆæœ¬çš„llama-cpp-python...")
    
    try:
        # å¸è½½ç°æœ‰ç‰ˆæœ¬
        logger.info("ğŸ“¦ å¸è½½ç°æœ‰ç‰ˆæœ¬...")
        subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', 'llama-cpp-python'], 
                      capture_output=True)
        
        # è®¾ç½®ç¼–è¯‘ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        env.update({
            'CMAKE_ARGS': '-DGGML_CUDA=ON -DCMAKE_CUDA_ARCHITECTURES=75;80;86;89',
            'FORCE_CMAKE': '1',
            'ARCHFLAGS': '-arch x86_64'
        })
        
        # å®‰è£…GPUç‰ˆæœ¬
        logger.info("ğŸ“¦ å®‰è£…GPUç‰ˆæœ¬...")
        cmd = [
            sys.executable, '-m', 'pip', 'install', 
            'llama-cpp-python', '--upgrade', '--no-cache-dir', '--force-reinstall',
            '--extra-index-url', 'https://abetlen.github.io/llama-cpp-python/whl/cu121'
        ]
        
        result = subprocess.run(cmd, env=env, capture_output=True, text=True, timeout=600)
        
        if result.returncode == 0:
            logger.info("âœ… llama-cpp-python GPUç‰ˆæœ¬å®‰è£…æˆåŠŸ")
            return True
        else:
            logger.error(f"âŒ å®‰è£…å¤±è´¥: {result.stderr}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ é‡æ–°å®‰è£…å¤±è´¥: {e}")
        return False

def test_gpu_loading():
    """æµ‹è¯•GPUåŠ è½½"""
    logger.info("ğŸ§ª æµ‹è¯•GPUåŠ è½½...")
    
    try:
        from llama_cpp import Llama
        logger.info(f"âœ… llama-cpp-pythonå¯¼å…¥æˆåŠŸ")
        
        # åˆ›å»ºä¸€ä¸ªæµ‹è¯•æ¨¡å‹å®ä¾‹ï¼ˆä¸åŠ è½½å®é™…æ¨¡å‹ï¼‰
        logger.info("ğŸ”§ æµ‹è¯•GPUé…ç½®...")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡å‹æ–‡ä»¶
        model_dir = "/runpod-volume/text_models"
        if os.path.exists(model_dir):
            model_files = [f for f in os.listdir(model_dir) if f.endswith('.gguf')]
            if model_files:
                model_path = os.path.join(model_dir, model_files[0])
                logger.info(f"ğŸ¯ æµ‹è¯•æ¨¡å‹: {model_path}")
                
                # åˆ›å»ºæ¨¡å‹å®ä¾‹è¿›è¡Œæµ‹è¯•
                test_model = Llama(
                    model_path=model_path,
                    n_gpu_layers=-1,  # å¼ºåˆ¶æ‰€æœ‰å±‚åˆ°GPU
                    n_ctx=2048,       # å°ä¸Šä¸‹æ–‡ç”¨äºæµ‹è¯•
                    verbose=True      # æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
                )
                
                logger.info("âœ… GPUæ¨¡å‹åŠ è½½æµ‹è¯•æˆåŠŸ")
                del test_model  # é‡Šæ”¾å†…å­˜
                return True
            else:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œè·³è¿‡åŠ è½½æµ‹è¯•")
                return True
        else:
            logger.warning("âš ï¸ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡åŠ è½½æµ‹è¯•")
            return True
            
    except Exception as e:
        logger.error(f"âŒ GPUåŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æœ€ç»ˆGPUä¿®å¤...")
    
    success = True
    
    # 1. æ£€æŸ¥ç³»ç»Ÿæ¶æ„
    if not check_system_architecture():
        logger.warning("âš ï¸ æ¶æ„é—®é¢˜ï¼Œå·²è®¾ç½®å¼ºåˆ¶x86_64ç¯å¢ƒå˜é‡")
    
    # 2. è®¾ç½®CUDAç¯å¢ƒ
    setup_cuda_environment()
    
    # 3. æ£€æŸ¥NVIDIAé©±åŠ¨
    if not check_nvidia_driver():
        logger.error("âŒ NVIDIAé©±åŠ¨æ£€æŸ¥å¤±è´¥")
        success = False
    
    # 4. é‡æ–°å®‰è£…llama-cpp-python
    if not reinstall_llama_cpp_python():
        logger.error("âŒ llama-cpp-pythoné‡æ–°å®‰è£…å¤±è´¥")
        success = False
    
    # 5. æµ‹è¯•GPUåŠ è½½
    if not test_gpu_loading():
        logger.error("âŒ GPUåŠ è½½æµ‹è¯•å¤±è´¥")
        success = False
    
    if success:
        logger.info("ğŸ‰ æœ€ç»ˆGPUä¿®å¤å®Œæˆï¼")
        logger.info("ğŸ“‹ ä¿®å¤æ‘˜è¦:")
        logger.info("  âœ“ å¼ºåˆ¶x86_64æ¶æ„ç¯å¢ƒå˜é‡")
        logger.info("  âœ“ CUDAç¯å¢ƒå˜é‡é…ç½®")
        logger.info("  âœ“ NVIDIAé©±åŠ¨æ£€æŸ¥")
        logger.info("  âœ“ GPUç‰ˆæœ¬llama-cpp-pythonå®‰è£…")
        logger.info("  âœ“ GPUåŠ è½½æµ‹è¯•")
        logger.info("")
        logger.info("ğŸ”¥ ç°åœ¨æ‰€æœ‰æ¨¡å‹å±‚éƒ½åº”è¯¥åŠ è½½åˆ°GPUè€Œä¸æ˜¯CPUï¼")
        return 0
    else:
        logger.error("âŒ ä¿®å¤è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 