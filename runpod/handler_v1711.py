#!/usr/bin/env python3
"""
RunPod Handler for version 1.7.11
åŸºäºæœ€æ–°çš„RunPod Python SDK
åŒ…å«GPUç›‘æ§åŠŸèƒ½
"""

import runpod
import os
import sys
import subprocess
import json
import time
import threading

def get_gpu_info():
    """è·å–GPUä½¿ç”¨æƒ…å†µ"""
    try:
        # ä½¿ç”¨nvidia-smiè·å–GPUä¿¡æ¯
        result = subprocess.run([
            'nvidia-smi', 
            '--query-gpu=index,name,memory.used,memory.total,utilization.gpu,temperature.gpu,power.draw',
            '--format=csv,noheader,nounits'
        ], capture_output=True, text=True, timeout=5)
        
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            gpu_info = []
            
            for line in lines:
                if line.strip():
                    parts = [p.strip() for p in line.split(',')]
                    if len(parts) >= 7:
                        gpu_info.append({
                            'index': parts[0],
                            'name': parts[1],
                            'memory_used_mb': parts[2],
                            'memory_total_mb': parts[3],
                            'utilization_percent': parts[4],
                            'temperature_c': parts[5],
                            'power_draw_w': parts[6]
                        })
            
            return gpu_info
        else:
            return [{'error': 'nvidia-smi command failed'}]
            
    except subprocess.TimeoutExpired:
        return [{'error': 'nvidia-smi timeout'}]
    except FileNotFoundError:
        return [{'error': 'nvidia-smi not found'}]
    except Exception as e:
        return [{'error': f'GPU info error: {str(e)}'}]

def log_gpu_status():
    """è®°å½•GPUçŠ¶æ€åˆ°æ—¥å¿—"""
    gpu_info = get_gpu_info()
    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
    
    print(f"\n=== GPU Status at {timestamp} ===")
    for i, gpu in enumerate(gpu_info):
        if 'error' in gpu:
            print(f"GPU {i}: {gpu['error']}")
        else:
            memory_used = float(gpu['memory_used_mb']) if gpu['memory_used_mb'] != 'N/A' else 0
            memory_total = float(gpu['memory_total_mb']) if gpu['memory_total_mb'] != 'N/A' else 1
            memory_percent = (memory_used / memory_total * 100) if memory_total > 0 else 0
            
            print(f"GPU {gpu['index']} ({gpu['name']}):")
            print(f"  Memory: {gpu['memory_used_mb']}MB / {gpu['memory_total_mb']}MB ({memory_percent:.1f}%)")
            print(f"  Utilization: {gpu['utilization_percent']}%")
            print(f"  Temperature: {gpu['temperature_c']}Â°C")
            print(f"  Power: {gpu['power_draw_w']}W")
    print("=" * 50)

def start_gpu_monitoring():
    """å¯åŠ¨GPUç›‘æ§çº¿ç¨‹"""
    def monitor_loop():
        while True:
            log_gpu_status()
            time.sleep(30)  # æ¯30ç§’è®°å½•ä¸€æ¬¡
    
    monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
    monitor_thread.start()
    print("ğŸ–¥ï¸ GPUç›‘æ§å·²å¯åŠ¨ï¼Œæ¯30ç§’è®°å½•ä¸€æ¬¡çŠ¶æ€")

def handler(job):
    """
    RunPod serverless handler function
    
    Args:
        job (dict): Job data containing 'input' and 'id'
        
    Returns:
        Any: The result to be returned to the client
    """
    try:
        # è·å–jobè¾“å…¥
        job_input = job.get("input", {})
        job_id = job.get("id", "unknown")
        
        # è®°å½•ä»»åŠ¡å¼€å§‹æ—¶çš„GPUçŠ¶æ€
        print(f"\nğŸš€ Job {job_id} started")
        log_gpu_status()
        
        # è·å–prompt
        prompt = job_input.get("prompt", "Hello from RunPod!")
        
        # æ¨¡æ‹Ÿä¸€äº›å¤„ç†æ—¶é—´ä»¥è§‚å¯ŸGPUä½¿ç”¨å˜åŒ–
        print(f"Job {job_id}: Processing prompt '{prompt}'")
        time.sleep(1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        # ç®€å•çš„echoå“åº”
        response = f"RunPod Echo (v1.7.11): {prompt}"
        
        # è®°å½•ä»»åŠ¡å®Œæˆæ—¶çš„GPUçŠ¶æ€
        print(f"Job {job_id}: Returning response '{response}'")
        log_gpu_status()
        print(f"âœ… Job {job_id} completed\n")
        
        # ç›´æ¥è¿”å›å­—ç¬¦ä¸²ï¼ŒRunPodä¼šè‡ªåŠ¨åŒ…è£…
        return response
        
    except Exception as e:
        error_msg = f"Handler error: {str(e)}"
        print(f"ERROR: {error_msg}")
        log_gpu_status()  # é”™è¯¯æ—¶ä¹Ÿè®°å½•GPUçŠ¶æ€
        return {"error": error_msg}

# å¯åŠ¨RunPod serverless
if __name__ == "__main__":
    print("=== RunPod Handler v1.7.11 Starting ===")
    print(f"Python version: {sys.version}")
    print(f"RunPod version: {getattr(runpod, '__version__', 'unknown')}")
    
    # å¯åŠ¨GPUç›‘æ§
    start_gpu_monitoring()
    
    # è®°å½•åˆå§‹GPUçŠ¶æ€
    print("\nğŸ” Initial GPU Status:")
    log_gpu_status()
    
    print("ğŸš€ Starting RunPod serverless...")
    # å¯åŠ¨serverless
    runpod.serverless.start({"handler": handler}) 