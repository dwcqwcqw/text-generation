# ç»¼åˆä¿®å¤ç‰ˆDockerfile - è§£å†³GPUå…¼å®¹æ€§å’Œå‰ç«¯æ¨¡å‹é€‰æ‹©é—®é¢˜
FROM nvidia/cuda:12.3-devel-ubuntu22.04

# é˜²æ­¢æ—¶åŒºé…ç½®äº¤äº’
ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=UTC

# åŸºç¡€ç¯å¢ƒå˜é‡
ENV GGML_CUDA=1
ENV CUDA_VISIBLE_DEVICES=0
ENV FORCE_CMAKE=1

# åŸºç¡€ç³»ç»Ÿæ›´æ–°å’Œä¾èµ–å®‰è£…
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    python3-dev \
    build-essential \
    cmake \
    git \
    wget \
    curl \
    ninja-build \
    pkg-config \
    libssl-dev \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Pythonä¾èµ–
RUN pip3 install --no-cache-dir \
    runpod \
    psutil \
    requests \
    numpy

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶æ‰€æœ‰ä¿®å¤è„šæœ¬
COPY comprehensive_fix.py /app/
COPY fix_cuda_rtx4090.py /app/
COPY handler_rtx4090.py /app/
COPY handler_llama_ai.py /app/handler.py

# è®¾ç½®æƒé™
RUN chmod +x /app/comprehensive_fix.py
RUN chmod +x /app/fix_cuda_rtx4090.py

# è¿è¡Œç»¼åˆä¿®å¤è„šæœ¬
RUN python3 /app/comprehensive_fix.py

# åˆ›å»ºæ¨¡å‹ç›®å½•
RUN mkdir -p /runpod-volume/text_models

# å¥åº·æ£€æŸ¥è„šæœ¬
COPY <<EOF /app/health_check.py
#!/usr/bin/env python3
import sys
import subprocess
import os

def health_check():
    try:
        # æ£€æŸ¥CUDA
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode != 0:
            print("âŒ NVIDIAé©±åŠ¨æ£€æŸ¥å¤±è´¥")
            return False
            
        # æ£€æŸ¥GPUå‹å·å’Œè®¡ç®—èƒ½åŠ›
        gpu_result = subprocess.run(['nvidia-smi', '--query-gpu=name,compute_cap', '--format=csv,noheader'], 
                                  capture_output=True, text=True)
        if gpu_result.returncode == 0:
            gpu_info = gpu_result.stdout.strip()
            print(f"ğŸ¯ GPUä¿¡æ¯: {gpu_info}")
        
        # æ£€æŸ¥llama-cpp-python
        import llama_cpp
        print(f"âœ… llama-cpp-python: {llama_cpp.__version__}")
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        print(f"GGML_CUDA: {os.environ.get('GGML_CUDA', 'NOT SET')}")
        print(f"CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES', 'NOT SET')}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = health_check()
    sys.exit(0 if success else 1)
EOF

RUN chmod +x /app/health_check.py

# è¿è¡Œå¥åº·æ£€æŸ¥
RUN python3 /app/health_check.py

# å¯åŠ¨è„šæœ¬
COPY <<EOF /app/start.sh
#!/bin/bash
set -e

echo "ğŸš€ å¯åŠ¨AIæ–‡æœ¬ç”ŸæˆæœåŠ¡"
echo "ğŸ“Š ç³»ç»Ÿä¿¡æ¯:"
echo "  - å®¹å™¨æ¶æ„: $(uname -m)"
echo "  - Pythonç‰ˆæœ¬: $(python3 --version)"

echo "ğŸ“Š GPUä¿¡æ¯:"
nvidia-smi --query-gpu=name,memory.total,compute_cap --format=csv

echo "ğŸ“Š ç¯å¢ƒå˜é‡:"
echo "  - GGML_CUDA: $GGML_CUDA"
echo "  - CUDA_VISIBLE_DEVICES: $CUDA_VISIBLE_DEVICES"
echo "  - CMAKE_CUDA_ARCHITECTURES: ${CMAKE_CUDA_ARCHITECTURES:-auto}"

echo "ğŸ§ª æœ€ç»ˆéªŒè¯:"
python3 /app/health_check.py

echo "ğŸš€ å¯åŠ¨Handler"
exec python3 /app/handler.py
EOF

RUN chmod +x /app/start.sh

# ç«¯å£
EXPOSE 8000

# å¯åŠ¨æœåŠ¡
CMD ["/app/start.sh"] 