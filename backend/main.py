from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import httpx
import boto3
import json
import uuid
from datetime import datetime, timedelta
import os
from dotenv import load_dotenv
import logging
import asyncio
from botocore.client import Config
import uvicorn
import base64
import tempfile
from fastapi import UploadFile, File

# å°è¯•åŠ è½½.envæ–‡ä»¶ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ä¹Ÿä¸ä¼šæŠ¥é”™
load_dotenv("config.env", override=True)
load_dotenv(".env", override=False)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="AI Chat API", version="1.0.0")

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥è®¾ç½®å…·ä½“çš„åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é…ç½®
RUNPOD_API_KEY = os.getenv("RUNPOD_API_KEY")
RUNPOD_ENDPOINT = os.getenv("RUNPOD_ENDPOINT", "https://api.runpod.ai/v2/4cx6jtjdx6hdhr/runsync")
MINIMAX_API_KEY = os.getenv("MINIMAX_API_KEY", "eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJHcm91cE5hbWUiOiJCRUkgTEkiLCJVc2VyTmFtZSI6IkJFSSBMSSIsIkFjY291bnQiOiIiLCJTdWJqZWN0SUQiOiIxOTI1MDI1MzAyNDAwOTk1NjQ0IiwiUGhvbmUiOiIiLCJHcm91cElEIjoiMTkyNTAyNTMwMjM5MjYwNzAzNiIsIlBhZ2VOYW1lIjoiIiwiTWFpbCI6ImJhaWxleWxpYmVpQGdtYWlsLmNvbSIsIkNyZWF0ZVRpbWUiOiIyMDI1LTA1LTIxIDEyOjIyOjI4IiwiVG9rZW5UeXBlIjoxLCJpc3MiOiJtaW5pbWF4In0.cMEP1g8YBLysihnD5RfmqtxGAGfR3XYxdXOAHurxoV5u92-ze8j5Iv1hc7O9qgFAoZyi2-eKRl6iRF3JM_IE1RQ6GXmfQnpr4a0VINu7c2GDW-x_4I-7CTHQTAmXfZOp6bVMbFvZqQDS9mzMexYDcFOghwJm1jFKhisU3J4996BqxC6R_u1J15yWkAb0Y5SX18hlYBEuO8MYPjAECSAcSthXIPxo4KQmd1LPuC2URnlhHBa6kvV0pZGp9tggSUlabyQaliCky8fxfOgyJc1YThQybg3iJ2VlYNnIhSj73SZ3pl6nB1unoiCsusAY0_mbzgcAiTd2rpKTh9xmUtcIxw")
MINIMAX_GROUP_ID = os.getenv("MINIMAX_GROUP_ID", "1925025302392607036")
CLOUDFLARE_ACCESS_KEY = os.getenv("CLOUDFLARE_ACCESS_KEY", "5885b29961ce9fc2b593139d9de52f81")
CLOUDFLARE_SECRET_KEY = os.getenv("CLOUDFLARE_SECRET_KEY", "a4415c670e669229db451ea7b38544c0a2e44dbe630f1f35f99f28a27593d181")
S3_ENDPOINT = os.getenv("S3_ENDPOINT", "https://c7c141ce43d175e60601edc46d904553.r2.cloudflarestorage.com")
R2_BUCKET = os.getenv("R2_BUCKET", "text-generation")

# Cloudflare R2é…ç½®
R2_CONFIG = {
    'access_key_id': '5885b29961ce9fc2b593139d9de52f81',
    'secret_access_key': 'a4415c670e669229db451ea7b38544c0a2e44dbe630f1f35f99f28a27593d181',
    'endpoint_url': 'https://c7c141ce43d175e60601edc46d904553.r2.cloudflarestorage.com',
    'bucket_name': 'text-generation',
    'region': 'auto'
}

# åˆå§‹åŒ–R2å®¢æˆ·ç«¯
try:
    r2_client = boto3.client(
        's3',
        endpoint_url=R2_CONFIG['endpoint_url'],
        aws_access_key_id=R2_CONFIG['access_key_id'],
        aws_secret_access_key=R2_CONFIG['secret_access_key'],
        region_name=R2_CONFIG['region'],
        config=Config(signature_version='s3v4')
    )
    logger.info("âœ… R2å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    logger.error(f"âŒ R2å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    r2_client = None

# Pydanticæ¨¡å‹
class Message(BaseModel):
    id: str
    content: str
    role: str  # 'user' or 'assistant'
    timestamp: datetime
    model: Optional[str] = None

class ChatSession(BaseModel):
    id: str
    title: str
    messages: List[Message]
    created_at: datetime
    updated_at: datetime
    metadata: Optional[dict] = {}

class ChatSaveRequest(BaseModel):
    chat_id: str
    messages: List[Message]
    metadata: Optional[dict] = {}

class ChatRequest(BaseModel):
    prompt: str
    model: str = "gpt2"
    max_length: int = 1024
    temperature: float = 0.7

class ChatRequestLegacy(BaseModel):
    message: str
    model: str = "L3.2-8X3B"
    temperature: Optional[float] = 0.7
    max_tokens: Optional[int] = 2048
    persona: Optional[str] = "default"

class ChatResponse(BaseModel):
    response: str
    model: str
    timestamp: datetime

class SimpleResponse(BaseModel):
    output: str
    generated_text: str

class GenerateRequest(BaseModel):
    prompt: str
    model: str = "L3.2-8X3B"  
    temperature: Optional[float] = 0.7
    max_tokens: Optional[int] = 2048
    persona: Optional[str] = "default"

class ChatRecord(BaseModel):
    chat_id: str
    messages: List[Message]
    metadata: Dict[str, Any] = {}

class ChatHistoryResponse(BaseModel):
    success: bool
    chats: List[Dict[str, Any]] = []
    error: Optional[str] = None

class STTRequest(BaseModel):
    audio_data: str  # base64 encoded audio
    format: str = "webm"  # webm, mp3, wav, etc.

class TTSRequest(BaseModel):
    text: str
    voice_id: str = "male-qn-qingse"
    speed: float = 1.0
    volume: float = 1.0
    pitch: int = 0

class STTResponse(BaseModel):
    success: bool
    text: str = ""
    error: Optional[str] = None

class TTSResponse(BaseModel):
    success: bool
    audio_url: Optional[str] = None
    audio_data: Optional[str] = None  # base64 encoded
    error: Optional[str] = None

# R2å­˜å‚¨å®¢æˆ·ç«¯
def get_r2_client():
    try:
        return boto3.client(
            's3',
            endpoint_url=S3_ENDPOINT,
            aws_access_key_id=CLOUDFLARE_ACCESS_KEY,
            aws_secret_access_key=CLOUDFLARE_SECRET_KEY,
            region_name='auto'
        )
    except Exception as e:
        print(f"Failed to create R2 client: {e}")
        return None

@app.get("/")
async def root():
    return {"message": "AI Chat API is running", "endpoints": ["/chat", "/health", "/models"]}

@app.get("/health")
async def health_check():
    r2_status = "connected" if r2_client else "disconnected"
    return {
        "status": "healthy",
        "r2_storage": r2_status,
        "timestamp": datetime.now().isoformat()
    }

@app.post("/chat")
async def chat(request: ChatRequest):
    """å¤„ç†èŠå¤©è¯·æ±‚ - ç®€åŒ–ç‰ˆæœ¬"""
    try:
        print(f"Received chat request: {request}")
        
        # æ¨¡æ‹ŸAIå›å¤ - å¦‚æœRunPodä¸å¯ç”¨
        if not RUNPOD_API_KEY or not RUNPOD_ENDPOINT:
            ai_response = f"Hello! You said: '{request.prompt}'. This is a test response from {request.model}."
            return {
                "output": ai_response,
                "response": ai_response,
                "generated_text": ai_response,
                "model": request.model,
                "timestamp": datetime.now()
            }
        
        # æ ¹æ®æ¨¡å‹IDè®¾ç½®æ­£ç¡®çš„æ¨¡å‹è·¯å¾„
        model_paths = {
            "L3.2-8X3B": "/runpod-volume/text_models/L3.2-8X3B.gguf",
            "L3.2-8X4B": "/runpod-volume/text_models/L3.2-8X4B.gguf"
        }
        
        model_path = model_paths.get(request.model, "/runpod-volume/text_models/L3.2-8X3B.gguf")
        
        # å°è¯•è°ƒç”¨RunPod API
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                # æ„å»ºé€‚åˆLlamaæ¨¡å‹çš„æç¤ºè¯
                llama_prompt = f"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful, harmless, and honest assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n{request.prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n"
                
                runpod_payload = {
                    "input": {
                        "model_path": model_path,
                        "prompt": llama_prompt,
                        "max_tokens": request.max_length,
                        "temperature": request.temperature,
                        "top_p": 0.9,
                        "repeat_penalty": 1.05,
                        "stop": ["<|eot_id|>", "<|end_of_text|>", "<|start_header_id|>"],
                        "stream": False
                    }
                }
                
                headers = {
                    "Authorization": f"Bearer {RUNPOD_API_KEY}",
                    "Content-Type": "application/json"
                }
                
                print(f"Sending to RunPod: {RUNPOD_ENDPOINT}")
                print(f"Model path: {model_path}")
                
                response = await client.post(
                    RUNPOD_ENDPOINT,
                    json=runpod_payload,
                    headers=headers
                )
                
                print(f"RunPod response status: {response.status_code}")
                
                if response.status_code == 200:
                    result = response.json()
                    print(f"RunPod result: {result}")
                    
                    if result.get("status") == "COMPLETED":
                        ai_response = result.get("output", {}).get("text", "").strip()
                        
                        # æ¸…ç†å“åº”ï¼Œç§»é™¤æç¤ºè¯æ ¼å¼
                        if ai_response:
                            # ç§»é™¤å¯èƒ½çš„ç³»ç»Ÿæç¤ºè¯æ®‹ç•™
                            ai_response = ai_response.replace(llama_prompt, "").strip()
                            
                            return {
                                "output": ai_response,
                                "response": ai_response,
                                "generated_text": ai_response,
                                "model": request.model,
                                "timestamp": datetime.now()
                            }
                    else:
                        print(f"RunPod job status: {result.get('status')}")
                        if result.get("error"):
                            print(f"RunPod error: {result.get('error')}")
                
                # å¦‚æœRunPodå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå›å¤
                print(f"RunPod API failed: {response.status_code}")
                error_text = await response.text()
                print(f"Error response: {error_text}")
                
        except Exception as e:
            print(f"RunPod error: {e}")
        
        # ä½¿ç”¨æ¨¡æ‹Ÿå›å¤ä½œä¸ºåå¤‡ - é’ˆå¯¹Llamaæ¨¡å‹çš„é«˜è´¨é‡å›å¤
        llama_responses = [
            f"I understand you're asking about '{request.prompt}'. Based on my training, I can provide some insights on this topic.",
            f"That's an interesting question about '{request.prompt}'. Let me share my perspective on this.",
            f"Regarding '{request.prompt}', I can offer several viewpoints to consider.",
            f"Thank you for your question about '{request.prompt}'. Here's what I think about this topic.",
            f"I appreciate your inquiry about '{request.prompt}'. Allow me to elaborate on this subject."
        ]
        
        detailed_responses = [
            "This is a complex topic that involves multiple considerations. From what I understand, there are several key factors to keep in mind when approaching this subject.",
            "Based on my knowledge, this area has several important aspects worth exploring. The key is to consider both the theoretical framework and practical applications.",
            "This is an area where different approaches can yield different results. It's important to consider the context and specific requirements of your situation.",
            "From my analysis, this topic encompasses various dimensions that are worth examining carefully. Each aspect contributes to the overall understanding.",
            "This subject has evolved significantly over time, and there are multiple schools of thought on the best approaches to consider."
        ]
        
        conclusions = [
            " Would you like me to dive deeper into any specific aspect of this topic?",
            " I'd be happy to explore any particular area of interest you might have.",
            " Is there a specific angle or perspective you'd like me to focus on?",
            " Please let me know if you'd like me to elaborate on any particular point.",
            " Feel free to ask for more details on any aspect that interests you."
        ]
        
        import random
        intro = random.choice(llama_responses)
        body = random.choice(detailed_responses)
        conclusion = random.choice(conclusions)
        
        ai_response = f"{intro}\n\n{body}{conclusion}"
        
        # ä¿å­˜èŠå¤©è®°å½•
        try:
            await save_simple_chat(request.prompt, ai_response, request.model)
        except Exception as e:
            print(f"Failed to save chat: {e}")
        
        return {
            "output": ai_response,
            "response": ai_response, 
            "generated_text": ai_response,
            "model": request.model,
            "timestamp": datetime.now()
        }
        
    except Exception as e:
        print(f"Chat error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/chat/legacy", response_model=ChatResponse)
async def chat_legacy(request: ChatRequestLegacy):
    """å¤„ç†èŠå¤©è¯·æ±‚ - åŸç‰ˆæœ¬å…¼å®¹"""
    try:
        # è½¬æ¢ä¸ºæ–°æ ¼å¼
        chat_req = ChatRequest(
            prompt=request.message,
            model=request.model,
            max_length=request.max_tokens,
            temperature=request.temperature
        )
        
        result = await chat(chat_req)
        
        return ChatResponse(
            response=result.get("response", ""),
            model=request.model,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        print(f"Legacy chat error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

async def save_simple_chat(prompt: str, response: str, model: str):
    """ä¿å­˜èŠå¤©è®°å½•åˆ°Cloudflare R2"""
    try:
        if not r2_client:
            return
        
        chat_session = {
            "id": str(uuid.uuid4()),
            "timestamp": datetime.now().isoformat(),
            "model": model,
            "prompt": prompt,
            "response": response
        }
        
        # ä½¿ç”¨æ—¥æœŸä½œä¸ºæ–‡ä»¶å¤¹ç»“æ„
        date_prefix = datetime.now().strftime("%Y/%m/%d")
        key = f"chats/{date_prefix}/{chat_session['id']}.json"
        
        r2_client.put_object(
            Bucket=R2_BUCKET,
            Key=key,
            Body=json.dumps(chat_session, ensure_ascii=False),
            ContentType='application/json'
        )
        
        print(f"Chat saved to R2: {key}")
        
    except Exception as e:
        print(f"R2 save error: {e}")

async def save_chat_to_r2(request: ChatRequestLegacy, response: str):
    """ä¿å­˜èŠå¤©è®°å½•åˆ°Cloudflare R2"""
    try:
        if not r2_client:
            return
        
        chat_session = {
            "id": str(uuid.uuid4()),
            "timestamp": datetime.now().isoformat(),
            "model": request.model,
            "messages": [
                {
                    "role": "user",
                    "content": request.message,
                    "timestamp": datetime.now().isoformat()
                },
                {
                    "role": "assistant", 
                    "content": response,
                    "timestamp": datetime.now().isoformat(),
                    "model": request.model
                }
            ]
        }
        
        # ä½¿ç”¨æ—¥æœŸä½œä¸ºæ–‡ä»¶å¤¹ç»“æ„
        date_prefix = datetime.now().strftime("%Y/%m/%d")
        key = f"chats/{date_prefix}/{chat_session['id']}.json"
        
        r2_client.put_object(
            Bucket=R2_BUCKET,
            Key=key,
            Body=json.dumps(chat_session, ensure_ascii=False),
            ContentType='application/json'
        )
        
        print(f"Chat saved to R2: {key}")
        
    except Exception as e:
        print(f"R2 save error: {e}")

@app.get("/models")
async def get_models():
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    models = [
        {
            "id": "L3.2-8X3B",
            "name": "Llama-3.2-8X3B",
            "description": "Dark Champion Instruct MOE (18.4B parameters)",
            "parameters": "18.4B",
            "context_length": "128k",
            "model_path": "/runpod-volume/text_models/L3.2-8X3B.gguf"
        },
        {
            "id": "L3.2-8X4B",
            "name": "Llama-3.2-8X4B", 
            "description": "Dark Champion Instruct V2 MOE (21B parameters)",
            "parameters": "21B",
            "context_length": "128k",
            "model_path": "/runpod-volume/text_models/L3.2-8X4B.gguf"
        }
    ]
    return {"models": models}

@app.get("/chat/history/{date}")
async def get_chat_history(date: str):
    """è·å–æŒ‡å®šæ—¥æœŸçš„èŠå¤©å†å²"""
    try:
        if not r2_client:
            return {"chats": [], "message": "Storage not available"}
        
        # åˆ—å‡ºæŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰èŠå¤©æ–‡ä»¶
        prefix = f"chats/{date}/"
        
        response = r2_client.list_objects_v2(
            Bucket=R2_BUCKET,
            Prefix=prefix
        )
        
        chats = []
        if 'Contents' in response:
            for obj in response['Contents']:
                try:
                    file_response = r2_client.get_object(
                        Bucket=R2_BUCKET,
                        Key=obj['Key']
                    )
                    chat_data = json.loads(file_response['Body'].read())
                    chats.append(chat_data)
                except Exception as e:
                    print(f"Error reading chat file {obj['Key']}: {e}")
        
        return {"chats": chats}
        
    except Exception as e:
        print(f"History error: {e}")
        return {"chats": [], "error": str(e)}

@app.post("/chat/save")
async def save_chat(chat_record: ChatRecord):
    """ä¿å­˜èŠå¤©è®°å½•åˆ°R2"""
    try:
        if not r2_client:
            raise HTTPException(status_code=500, detail="R2å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        
        # ç”Ÿæˆæ–‡ä»¶è·¯å¾„
        date_str = datetime.now().strftime('%Y-%m-%d')
        file_key = f"chats/{date_str}/{chat_record.chat_id}.json"
        
        # å‡†å¤‡æ•°æ®
        chat_data = {
            "id": chat_record.chat_id,
            "timestamp": datetime.now().isoformat(),
            "title": next((msg.content[:30] + "..." for msg in chat_record.messages if msg.role == "user"), "æ–°å¯¹è¯"),
            "messages": [msg.dict() for msg in chat_record.messages],
            "metadata": chat_record.metadata
        }
        
        # ä¿å­˜åˆ°R2
        response = r2_client.put_object(
            Bucket=R2_CONFIG['bucket_name'],
            Key=file_key,
            Body=json.dumps(chat_data, ensure_ascii=False, indent=2),
            ContentType='application/json'
        )
        
        logger.info(f"âœ… èŠå¤©è®°å½•ä¿å­˜æˆåŠŸ: {file_key}")
        return {
            "success": True,
            "chat_id": chat_record.chat_id,
            "file_key": file_key,
            "etag": response.get('ETag')
        }
        
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜èŠå¤©è®°å½•å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ä¿å­˜å¤±è´¥: {str(e)}")

@app.get("/chat/load/{chat_id}")
async def load_chat(chat_id: str):
    """ä»R2åŠ è½½èŠå¤©è®°å½•"""
    try:
        if not r2_client:
            raise HTTPException(status_code=500, detail="R2å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        
        # å°è¯•å¤šä¸ªå¯èƒ½çš„æ—¥æœŸè·¯å¾„
        for days_back in range(30):  # æœç´¢æœ€è¿‘30å¤©
            date_str = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')
            file_key = f"chats/{date_str}/{chat_id}.json"
            
            try:
                response = r2_client.get_object(
                    Bucket=R2_CONFIG['bucket_name'],
                    Key=file_key
                )
                
                chat_data = json.loads(response['Body'].read().decode('utf-8'))
                logger.info(f"âœ… èŠå¤©è®°å½•åŠ è½½æˆåŠŸ: {file_key}")
                return {
                    "success": True,
                    "data": chat_data
                }
                
            except r2_client.exceptions.NoSuchKey:
                continue
        
        raise HTTPException(status_code=404, detail="èŠå¤©è®°å½•ä¸å­˜åœ¨")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ åŠ è½½èŠå¤©è®°å½•å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åŠ è½½å¤±è´¥: {str(e)}")

@app.get("/chat/history/{date_str}")
async def list_chats(date_str: str):
    """åˆ—å‡ºæŒ‡å®šæ—¥æœŸçš„èŠå¤©è®°å½•"""
    try:
        if not r2_client:
            raise HTTPException(status_code=500, detail="R2å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        
        # æ ¼å¼åŒ–æ—¥æœŸ
        formatted_date = date_str.replace('/', '-')
        prefix = f"chats/{formatted_date}/"
        
        # åˆ—å‡ºæ–‡ä»¶
        response = r2_client.list_objects_v2(
            Bucket=R2_CONFIG['bucket_name'],
            Prefix=prefix
        )
        
        chats = []
        if 'Contents' in response:
            for obj in response['Contents']:
                try:
                    # è·å–æ–‡ä»¶å†…å®¹
                    file_response = r2_client.get_object(
                        Bucket=R2_CONFIG['bucket_name'],
                        Key=obj['Key']
                    )
                    
                    chat_data = json.loads(file_response['Body'].read().decode('utf-8'))
                    
                    chats.append({
                        "id": chat_data.get("id"),
                        "title": chat_data.get("title", "æœªçŸ¥å¯¹è¯"),
                        "timestamp": chat_data.get("timestamp"),
                        "message_count": len(chat_data.get("messages", [])),
                        "metadata": chat_data.get("metadata", {})
                    })
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è§£æèŠå¤©æ–‡ä»¶å¤±è´¥ {obj['Key']}: {e}")
                    continue
        
        logger.info(f"âœ… è·å–èŠå¤©å†å²æˆåŠŸ: {len(chats)} æ¡è®°å½•")
        return {
            "success": True,
            "chats": sorted(chats, key=lambda x: x.get("timestamp", ""), reverse=True)
        }
        
    except Exception as e:
        logger.error(f"âŒ è·å–èŠå¤©å†å²å¤±è´¥: {e}")
        return {
            "success": True,
            "chats": []
        }

@app.delete("/chat/delete/{chat_id}")
async def delete_chat(chat_id: str):
    """åˆ é™¤èŠå¤©è®°å½•"""
    try:
        if not r2_client:
            raise HTTPException(status_code=500, detail="R2å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        
        # å°è¯•å¤šä¸ªå¯èƒ½çš„æ—¥æœŸè·¯å¾„
        deleted = False
        for days_back in range(30):
            date_str = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')
            file_key = f"chats/{date_str}/{chat_id}.json"
            
            try:
                r2_client.delete_object(
                    Bucket=R2_CONFIG['bucket_name'],
                    Key=file_key
                )
                deleted = True
                logger.info(f"âœ… èŠå¤©è®°å½•åˆ é™¤æˆåŠŸ: {file_key}")
                break
                
            except r2_client.exceptions.NoSuchKey:
                continue
        
        if not deleted:
            raise HTTPException(status_code=404, detail="èŠå¤©è®°å½•ä¸å­˜åœ¨")
        
        return {"success": True, "message": "èŠå¤©è®°å½•å·²åˆ é™¤"}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ åˆ é™¤èŠå¤©è®°å½•å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å¤±è´¥: {str(e)}")

@app.get("/chat/list")
async def list_recent_chats(days: int = 7):
    """åˆ—å‡ºæœ€è¿‘çš„èŠå¤©è®°å½•"""
    try:
        if not r2_client:
            return {"chats": [], "message": "Storage not available"}
        
        all_chats = []
        
        # æŸ¥æ‰¾æœ€è¿‘å‡ å¤©çš„èŠå¤©è®°å½•
        for days_back in range(days):
            date = (datetime.now() - timedelta(days=days_back)).strftime("%Y/%m/%d")
            prefix = f"chats/{date}/"
            
            try:
                response = r2_client.list_objects_v2(
                    Bucket=R2_BUCKET,
                    Prefix=prefix
                )
                
                if 'Contents' in response:
                    for obj in response['Contents']:
                        try:
                            file_response = r2_client.get_object(
                                Bucket=R2_BUCKET,
                                Key=obj['Key']
                            )
                            chat_data = json.loads(file_response['Body'].read())
                            
                            # æå–èŠå¤©æ‘˜è¦ä¿¡æ¯
                            first_user_msg = next(
                                (msg for msg in chat_data.get('messages', []) if msg.get('role') == 'user'),
                                None
                            )
                            
                            chat_summary = {
                                "id": chat_data.get('id'),
                                "title": first_user_msg.get('content', 'Untitled Chat')[:50] + '...' if first_user_msg else 'Empty Chat',
                                "timestamp": chat_data.get('timestamp'),
                                "message_count": len(chat_data.get('messages', [])),
                                "storage_key": obj['Key']
                            }
                            
                            all_chats.append(chat_summary)
                            
                        except Exception as e:
                            print(f"Error processing chat file {obj['Key']}: {e}")
                            continue
                            
            except Exception as e:
                print(f"Error listing chats for date {date}: {e}")
                continue
        
        # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
        all_chats.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        
        return {
            "chats": all_chats[:50],  # é™åˆ¶è¿”å›æœ€è¿‘50ä¸ªèŠå¤©
            "total": len(all_chats)
        }
        
    except Exception as e:
        print(f"List chats error: {e}")
        return {"chats": [], "error": str(e)}

@app.post("/speech/stt", response_model=STTResponse)
async def speech_to_text(request: STTRequest):
    """è¯­éŸ³è½¬æ–‡å­— - ä½¿ç”¨ Whisper-large-v3-turbo"""
    try:
        print(f"ğŸ¤ æ”¶åˆ°è¯­éŸ³è½¬æ–‡å­—è¯·æ±‚ï¼ŒéŸ³é¢‘æ ¼å¼: {request.format}")
        
        # è§£ç base64éŸ³é¢‘æ•°æ®
        try:
            audio_bytes = base64.b64decode(request.audio_data)
            print(f"ğŸ“Š éŸ³é¢‘æ•°æ®å¤§å°: {len(audio_bytes)} bytes")
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ•°æ®è§£ç å¤±è´¥: {e}")
            return STTResponse(success=False, error="æ— æ•ˆçš„éŸ³é¢‘æ•°æ®æ ¼å¼")
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix=f'.{request.format}', delete=False) as temp_file:
            temp_file.write(audio_bytes)
            temp_file_path = temp_file.name
        
        try:
            # è°ƒç”¨RunPod Whisper API
            if not RUNPOD_API_KEY:
                return STTResponse(success=False, error="RunPod API Keyæœªé…ç½®")
            
            # å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºbase64ç”¨äºAPIè°ƒç”¨
            with open(temp_file_path, 'rb') as audio_file:
                audio_base64 = base64.b64encode(audio_file.read()).decode('utf-8')
            
            # æ„å»ºRunPodè¯·æ±‚
            runpod_payload = {
                "input": {
                    "audio_data": audio_base64,
                    "format": request.format,
                    "model_path": "/runpod-volume/voice/whisper-large-v3-turbo",
                    "task": "transcribe",
                    "language": "auto"  # è‡ªåŠ¨æ£€æµ‹è¯­è¨€
                }
            }
            
            headers = {
                "Authorization": f"Bearer {RUNPOD_API_KEY}",
                "Content-Type": "application/json"
            }
            
            print(f"ğŸš€ è°ƒç”¨RunPod Whisper API...")
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    RUNPOD_ENDPOINT,
                    json=runpod_payload,
                    headers=headers
                )
                
                print(f"ğŸ“¡ RunPodå“åº”çŠ¶æ€: {response.status_code}")
                
                if response.status_code == 200:
                    result = response.json()
                    print(f"ğŸ“¦ RunPodå“åº”: {result}")
                    
                    if result.get("status") == "COMPLETED":
                        # æå–è½¬å½•æ–‡æœ¬
                        transcription = ""
                        if "output" in result:
                            if isinstance(result["output"], str):
                                transcription = result["output"]
                            elif isinstance(result["output"], dict):
                                transcription = result["output"].get("text", result["output"].get("transcription", ""))
                        
                        if transcription:
                            print(f"âœ… è¯­éŸ³è½¬æ–‡å­—æˆåŠŸ: {transcription}")
                            return STTResponse(success=True, text=transcription.strip())
                        else:
                            print("âš ï¸ æœªæ£€æµ‹åˆ°è¯­éŸ³å†…å®¹")
                            return STTResponse(success=False, error="æœªæ£€æµ‹åˆ°è¯­éŸ³å†…å®¹")
                    else:
                        error_msg = result.get("error", "è¯­éŸ³è¯†åˆ«å¤±è´¥")
                        print(f"âŒ RunPodä»»åŠ¡å¤±è´¥: {error_msg}")
                        return STTResponse(success=False, error=error_msg)
                else:
                    error_text = await response.text()
                    print(f"âŒ RunPod APIé”™è¯¯: {response.status_code} - {error_text}")
                    return STTResponse(success=False, error=f"APIè°ƒç”¨å¤±è´¥: {response.status_code}")
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(temp_file_path)
            except:
                pass
    
    except Exception as e:
        print(f"âŒ è¯­éŸ³è½¬æ–‡å­—å¤„ç†å¼‚å¸¸: {e}")
        return STTResponse(success=False, error=f"å¤„ç†å¼‚å¸¸: {str(e)}")

@app.post("/speech/tts", response_model=TTSResponse)
async def text_to_speech(request: TTSRequest):
    """æ–‡å­—è½¬è¯­éŸ³ - ä½¿ç”¨ MiniMax API"""
    try:
        print(f"ğŸ”Š æ”¶åˆ°æ–‡å­—è½¬è¯­éŸ³è¯·æ±‚: {request.text[:50]}...")
        
        if not request.text.strip():
            return TTSResponse(success=False, error="æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º")
        
        # æ„å»ºMiniMax TTSè¯·æ±‚
        minimax_url = f"https://api.minimax.io/v1/t2a_v2?GroupId={MINIMAX_GROUP_ID}"
        
        headers = {
            "Content-Type": "application/json", 
            "Authorization": f"Bearer {MINIMAX_API_KEY}"
        }
        
        payload = {
            "model": "speech-02-turbo",
            "text": request.text,
            "stream": False,
            "voice_setting": {
                "voice_id": request.voice_id,
                "speed": request.speed,
                "vol": request.volume,
                "pitch": request.pitch
            },
            "audio_setting": {
                "sample_rate": 32000,
                "bitrate": 128000,
                "format": "mp3",
                "channel": 1
            }
        }
        
        print(f"ğŸš€ è°ƒç”¨MiniMax TTS API...")
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(
                minimax_url,
                json=payload,
                headers=headers
            )
            
            print(f"ğŸ“¡ MiniMaxå“åº”çŠ¶æ€: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                print(f"ğŸ“¦ MiniMaxå“åº”: {result}")
                
                # æ£€æŸ¥å“åº”æ ¼å¼
                if "data" in result and "audio" in result["data"]:
                    # è·å–åå…­è¿›åˆ¶éŸ³é¢‘æ•°æ®
                    hex_audio = result["data"]["audio"]
                    
                    # è½¬æ¢ä¸ºå­—èŠ‚æ•°æ®
                    audio_bytes = bytes.fromhex(hex_audio)
                    
                    # è½¬æ¢ä¸ºbase64ç”¨äºå‰ç«¯æ’­æ”¾
                    audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
                    
                    print(f"âœ… æ–‡å­—è½¬è¯­éŸ³æˆåŠŸï¼ŒéŸ³é¢‘å¤§å°: {len(audio_bytes)} bytes")
                    return TTSResponse(success=True, audio_data=audio_base64)
                
                else:
                    print(f"âŒ MiniMaxå“åº”æ ¼å¼å¼‚å¸¸: {result}")
                    return TTSResponse(success=False, error="éŸ³é¢‘ç”Ÿæˆå¤±è´¥")
            
            else:
                error_text = await response.text()
                print(f"âŒ MiniMax APIé”™è¯¯: {response.status_code} - {error_text}")
                return TTSResponse(success=False, error=f"APIè°ƒç”¨å¤±è´¥: {response.status_code}")
    
    except Exception as e:
        print(f"âŒ æ–‡å­—è½¬è¯­éŸ³å¤„ç†å¼‚å¸¸: {e}")
        return TTSResponse(success=False, error=f"å¤„ç†å¼‚å¸¸: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    host = os.getenv("API_HOST", "0.0.0.0")
    port = int(os.getenv("API_PORT", 8000))
    debug = os.getenv("DEBUG", "false").lower() == "true"
    
    uvicorn.run(app, host=host, port=port, reload=debug) 